import pandas as pd
import warnings
import streamlit as st
from io import BytesIO

# --- ‡∏õ‡∏¥‡∏î Warning ‡∏Å‡∏ß‡∏ô‡πÉ‡∏à ---
pd.options.mode.chained_assignment = None  # ‡∏õ‡∏¥‡∏î SettingWithCopyWarning
warnings.simplefilter(action="ignore", category=FutureWarning)

st.set_page_config(page_title="Excel ‚Üí Parquet Merger", page_icon="üì¶", layout="centered")

st.title("üì¶ Merge Excel Sheets ‚Üí Parquet")
st.write("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel ‡πÅ‡∏•‡πâ‡∏ß‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏£‡∏ß‡∏°‡∏ó‡∏∏‡∏Å‡∏ä‡∏µ‡∏ó‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏ü‡∏•‡πå Parquet (‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Unnamed ‡πÅ‡∏•‡∏∞‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á)")

def merge_excel_to_parquet_bytes(uploaded_file) -> tuple[bytes, dict]:
    """
    ‡∏≠‡πà‡∏≤‡∏ô Excel ‡∏ó‡∏∏‡∏Å‡∏ä‡∏µ‡∏ó -> ‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î -> concat -> export parquet ‡πÄ‡∏õ‡πá‡∏ô bytes
    ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤: (parquet_bytes, stats_dict)
    """
    # ‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏∏‡∏Å‡∏ä‡∏µ‡∏ó‡πÄ‡∏õ‡πá‡∏ô dict {sheet_name: df}
    all_sheets = pd.read_excel(uploaded_file, sheet_name=None, dtype=str)

    all_data_frames = []
    per_sheet_rows = {}

    for sheet_name, df in all_sheets.items():
        # 1) ‡∏•‡∏ö‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå Unnamed (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç)
        df = df.loc[:, ~df.columns.astype(str).str.contains(r"^Unnamed")].copy()

        # 2) ‡∏•‡∏ö‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
        df = df.dropna(how="all")

        per_sheet_rows[sheet_name] = len(df)

        if len(df) > 0:
            all_data_frames.append(df)

    if not all_data_frames:
        raise ValueError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î (‡∏ó‡∏∏‡∏Å‡∏ä‡∏µ‡∏ó‡∏ß‡πà‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏´‡∏°‡∏î)")

    merged_df = pd.concat(all_data_frames, ignore_index=True)

    # export parquet ‡πÄ‡∏õ‡πá‡∏ô bytes
    buffer = BytesIO()
    merged_df.to_parquet(buffer, index=False, engine="pyarrow")
    parquet_bytes = buffer.getvalue()

    stats = {
        "sheet_count": len(all_sheets),
        "merged_rows": len(merged_df),
        "per_sheet_rows": per_sheet_rows,
        "parquet_size_mb": len(parquet_bytes) / (1024 * 1024),
    }
    return parquet_bytes, stats


uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Excel (.xlsx)", type=["xlsx"])

output_name = st.text_input("‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå Parquet ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î", value="merged_data.parquet")

if uploaded:
    st.info(f"‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î: {uploaded.name}")

    col1, col2 = st.columns([1, 1])
    with col1:
        run_btn = st.button("‚ñ∂Ô∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏ß‡∏°‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á", use_container_width=True)
    with col2:
        preview = st.checkbox("‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Preview)", value=False)

    if run_btn:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå / ‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• / ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡πÄ‡∏õ‡πá‡∏ô Parquet..."):
            try:
                parquet_bytes, stats = merge_excel_to_parquet_bytes(uploaded)

                st.success("‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå!")

                st.subheader("‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•")
                st.write(f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏µ‡∏ó‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: **{stats['sheet_count']}**")
                st.write(f"- ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏£‡∏ß‡∏°‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î: **{stats['merged_rows']}**")
                st.write(f"- ‡∏Ç‡∏ô‡∏≤‡∏î‡πÑ‡∏ü‡∏•‡πå Parquet: **{stats['parquet_size_mb']:.2f} MB**")

                with st.expander("‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ï‡πà‡∏≠‡∏ä‡∏µ‡∏ó"):
                    st.write(stats["per_sheet_rows"])

                # download
                st.download_button(
                    label="‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå Parquet",
                    data=parquet_bytes,
                    file_name=output_name if output_name.strip() else "merged_data.parquet",
                    mime="application/octet-stream",
                    use_container_width=True,
                )

                if preview:
                    # ‡∏≠‡πà‡∏≤‡∏ô parquet bytes ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤‡πÄ‡∏û‡∏∑‡πà‡∏≠ preview (‡∏Å‡∏±‡∏ô‡∏û‡∏•‡∏≤‡∏î‡∏Å‡∏£‡∏ì‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏ç‡πà)
                    df_preview = pd.read_parquet(BytesIO(parquet_bytes), engine="pyarrow")
                    st.subheader("Preview (‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á 200 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å)")
                    st.dataframe(df_preview.head(200), use_container_width=True)

            except Exception as e:
                st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
                st.exception(e)
else:
    st.caption("‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏´‡∏•‡∏≤‡∏¢‡∏ä‡∏µ‡∏ó‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏£‡∏ß‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡πÇ‡∏î‡∏¢‡∏ï‡πà‡∏≠‡πÅ‡∏ñ‡∏ß (append) ‡∏ó‡∏∏‡∏Å‡∏ä‡∏µ‡∏ó‡πÄ‡∏Ç‡πâ‡∏≤‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏±‡∏ô")
